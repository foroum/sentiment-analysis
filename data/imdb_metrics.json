{
  "best_model": "linear_svm",
  "models": {
    "logreg": {
      "val_accuracy": 0.8972,
      "test_accuracy": 0.89108,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8949    0.8862    0.8906     12500\n    POSITIVE     0.8873    0.8959    0.8916     12500\n\n    accuracy                         0.8911     25000\n   macro avg     0.8911    0.8911    0.8911     25000\nweighted avg     0.8911    0.8911    0.8911     25000\n"
    },
    "naive_bayes": {
      "val_accuracy": 0.8706,
      "test_accuracy": 0.86276,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8546    0.8743    0.8643     12500\n    POSITIVE     0.8713    0.8512    0.8612     12500\n\n    accuracy                         0.8628     25000\n   macro avg     0.8630    0.8628    0.8627     25000\nweighted avg     0.8630    0.8628    0.8627     25000\n"
    },
    "linear_svm": {
      "val_accuracy": 0.9022,
      "test_accuracy": 0.89312,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8923    0.8942    0.8932     12500\n    POSITIVE     0.8939    0.8921    0.8930     12500\n\n    accuracy                         0.8931     25000\n   macro avg     0.8931    0.8931    0.8931     25000\nweighted avg     0.8931    0.8931    0.8931     25000\n"
    }
  }
}