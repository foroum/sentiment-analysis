{
  "best_model": "linear_svm",
  "models": {
    "logreg": {
      "val_accuracy": 0.8972,
      "test_accuracy": 0.89092,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8947    0.8861    0.8904     12500\n    POSITIVE     0.8872    0.8958    0.8914     12500\n\n    accuracy                         0.8909     25000\n   macro avg     0.8910    0.8909    0.8909     25000\nweighted avg     0.8910    0.8909    0.8909     25000\n"
    },
    "naive_bayes": {
      "val_accuracy": 0.8706,
      "test_accuracy": 0.86268,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8544    0.8743    0.8643     12500\n    POSITIVE     0.8713    0.8510    0.8611     12500\n\n    accuracy                         0.8627     25000\n   macro avg     0.8629    0.8627    0.8627     25000\nweighted avg     0.8629    0.8627    0.8627     25000\n"
    },
    "linear_svm": {
      "val_accuracy": 0.9022,
      "test_accuracy": 0.893,
      "report": "              precision    recall  f1-score   support\n\n    NEGATIVE     0.8921    0.8942    0.8931     12500\n    POSITIVE     0.8939    0.8918    0.8929     12500\n\n    accuracy                         0.8930     25000\n   macro avg     0.8930    0.8930    0.8930     25000\nweighted avg     0.8930    0.8930    0.8930     25000\n"
    }
  }
}